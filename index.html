<!DOCTYPE html>
<html lang="pt-BR">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Reconhecimento Facial com face-api.js</title>
  <style>
    body {
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      height: 100vh;
      background-color: #222;
      color: white;
      font-family: sans-serif;
      margin: 0;
      position: relative;
    }

    video, canvas {
      width: 90%;
      max-width: 400px;
      border-radius: 8px;
    }

    video {
      border: 2px solid white;
    }

    canvas {
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      margin: auto;
      z-index: 1;
      pointer-events: none;
    }

    h1 {
      text-align: center;
      margin-top: 20px;
    }
  </style>
  <script defer src="face-api.min.js"></script>
</head>
<body>
  <h1>Reconhecimento Facial</h1>
  <video id="video" autoplay playsinline muted></video>
  <canvas id="overlayCanvas"></canvas>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('overlayCanvas');
    const MODEL_URL = './models';

    async function loadModels() {
      try {
        console.log("Carregando modelos...");
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
          faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
          faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),
          faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)
        ]);
        console.log("‚úÖ Modelos carregados com sucesso!");
      } catch (error) {
        console.error("‚ùå Erro ao carregar modelos:", error);
        alert("Erro ao carregar os modelos de detec√ß√£o facial.\n" +
              "Verifique se a pasta 'models' est√° presente e acess√≠vel.\n\n" +
              "Detalhes do erro: " + error.message);
        throw error;
      }
    }

    async function startVideo() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: 'user' },
          audio: false
        });
        video.srcObject = stream;
        console.log("üé• C√¢mera iniciada com sucesso.");
      } catch (error) {
        console.error("‚ùå Erro ao acessar a c√¢mera:", error);
        alert("Erro ao acessar a c√¢mera.\n" +
              "Verifique se voc√™ concedeu permiss√£o e se est√° em HTTPS ou localhost.\n\n" +
              "Detalhes: " + error.message);
        throw error;
      }
    }

    // --- MUDAN√áA 1: A fun√ß√£o de detec√ß√£o foi reestruturada para um loop mais eficiente ---
    async function runDetection() {
      // Verifica se o v√≠deo est√° tocando para evitar erros
      if (video.paused || video.ended) {
        return setTimeout(() => runDetection());
      }
      
      // --- MUDAN√áA 2: Op√ß√µes de detec√ß√£o para acelerar o processo ---
      // inputSize: Reduz o tamanho da imagem a ser analisada, aumentando muito a velocidade.
      // scoreThreshold: Evita detectar "falsos positivos" com baixa confian√ßa.
      const detectorOptions = new faceapi.TinyFaceDetectorOptions({
        inputSize: 320, // Quanto menor, mais r√°pido. 320 √© um bom equil√≠brio.
        scoreThreshold: 0.5 // Limiar de confian√ßa para detectar um rosto.
      });

      try {
        const detections = await faceapi
          .detectAllFaces(video, detectorOptions)
          .withFaceLandmarks()
          .withFaceExpressions();

        const displaySize = { width: video.clientWidth, height: video.clientHeight };
        faceapi.matchDimensions(canvas, displaySize);

        const resized = faceapi.resizeResults(detections, displaySize);
        
        const ctx = canvas.getContext('2d');
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        faceapi.draw.drawDetections(canvas, resized);
        faceapi.draw.drawFaceLandmarks(canvas, resized);
        faceapi.draw.drawFaceExpressions(canvas, resized);

      } catch (detectError) {
        console.warn("‚ö†Ô∏è Erro durante a detec√ß√£o:", detectError.message);
      }

      // --- MUDAN√áA 3: Usando requestAnimationFrame para um loop suave e sem sobrecarga ---
      // Em vez de setInterval, chamamos a pr√≥xima detec√ß√£o assim que a atual terminar.
      requestAnimationFrame(runDetection);
    }

    // Inicializa√ß√£o
    window.addEventListener('DOMContentLoaded', async () => {
      try {
        await loadModels();
        await startVideo();

        video.addEventListener('play', () => {
          // Ajusta as dimens√µes do canvas uma vez que o v√≠deo come√ßa a tocar
          const displaySize = { width: video.clientWidth, height: video.clientHeight };
          faceapi.matchDimensions(canvas, displaySize);
          
          // Inicia o loop de detec√ß√£o
          runDetection();
        });
      } catch (globalError) {
        console.log("‚ùå Inicializa√ß√£o interrompida por erro:", globalError.message);
      }
    });
  </script>
</body>
</html>
